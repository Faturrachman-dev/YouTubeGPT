{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "486 seconds is equal to 8.06 minutes\n"
     ]
    }
   ],
   "source": [
    "def seconds_to_minutes(seconds):\n",
    "    minutes = seconds // 60  # Integer division\n",
    "    remaining_seconds = seconds % 60\n",
    "\n",
    "    if remaining_seconds < 10:\n",
    "        return f\"{int(minutes)}.0{int(remaining_seconds)}\"\n",
    "    return f\"{int(minutes)}.{int(remaining_seconds)}\"\n",
    "\n",
    "# Example usage\n",
    "seconds = 486\n",
    "minutes = seconds_to_minutes(seconds)\n",
    "print(f\"{seconds} seconds is equal to {minutes}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<Stream: itag=\"18\" mime_type=\"video/mp4\" res=\"360p\" fps=\"30fps\" vcodec=\"avc1.42001E\" acodec=\"mp4a.40.2\" progressive=\"True\" type=\"video\">, <Stream: itag=\"313\" mime_type=\"video/webm\" res=\"2160p\" fps=\"30fps\" vcodec=\"vp9\" progressive=\"False\" type=\"video\">, <Stream: itag=\"401\" mime_type=\"video/mp4\" res=\"2160p\" fps=\"30fps\" vcodec=\"av01.0.12M.08\" progressive=\"False\" type=\"video\">, <Stream: itag=\"271\" mime_type=\"video/webm\" res=\"1440p\" fps=\"30fps\" vcodec=\"vp9\" progressive=\"False\" type=\"video\">, <Stream: itag=\"400\" mime_type=\"video/mp4\" res=\"1440p\" fps=\"30fps\" vcodec=\"av01.0.12M.08\" progressive=\"False\" type=\"video\">, <Stream: itag=\"137\" mime_type=\"video/mp4\" res=\"1080p\" fps=\"30fps\" vcodec=\"avc1.640028\" progressive=\"False\" type=\"video\">, <Stream: itag=\"248\" mime_type=\"video/webm\" res=\"1080p\" fps=\"30fps\" vcodec=\"vp9\" progressive=\"False\" type=\"video\">, <Stream: itag=\"399\" mime_type=\"video/mp4\" res=\"1080p\" fps=\"30fps\" vcodec=\"av01.0.08M.08\" progressive=\"False\" type=\"video\">, <Stream: itag=\"136\" mime_type=\"video/mp4\" res=\"720p\" fps=\"30fps\" vcodec=\"avc1.4d401f\" progressive=\"False\" type=\"video\">, <Stream: itag=\"247\" mime_type=\"video/webm\" res=\"720p\" fps=\"30fps\" vcodec=\"vp9\" progressive=\"False\" type=\"video\">, <Stream: itag=\"398\" mime_type=\"video/mp4\" res=\"720p\" fps=\"30fps\" vcodec=\"av01.0.05M.08\" progressive=\"False\" type=\"video\">, <Stream: itag=\"135\" mime_type=\"video/mp4\" res=\"480p\" fps=\"30fps\" vcodec=\"avc1.4d401f\" progressive=\"False\" type=\"video\">, <Stream: itag=\"244\" mime_type=\"video/webm\" res=\"480p\" fps=\"30fps\" vcodec=\"vp9\" progressive=\"False\" type=\"video\">, <Stream: itag=\"397\" mime_type=\"video/mp4\" res=\"480p\" fps=\"30fps\" vcodec=\"av01.0.04M.08\" progressive=\"False\" type=\"video\">, <Stream: itag=\"134\" mime_type=\"video/mp4\" res=\"360p\" fps=\"30fps\" vcodec=\"avc1.4d401e\" progressive=\"False\" type=\"video\">, <Stream: itag=\"243\" mime_type=\"video/webm\" res=\"360p\" fps=\"30fps\" vcodec=\"vp9\" progressive=\"False\" type=\"video\">, <Stream: itag=\"396\" mime_type=\"video/mp4\" res=\"360p\" fps=\"30fps\" vcodec=\"av01.0.01M.08\" progressive=\"False\" type=\"video\">, <Stream: itag=\"133\" mime_type=\"video/mp4\" res=\"240p\" fps=\"30fps\" vcodec=\"avc1.4d4015\" progressive=\"False\" type=\"video\">, <Stream: itag=\"242\" mime_type=\"video/webm\" res=\"240p\" fps=\"30fps\" vcodec=\"vp9\" progressive=\"False\" type=\"video\">, <Stream: itag=\"395\" mime_type=\"video/mp4\" res=\"240p\" fps=\"30fps\" vcodec=\"av01.0.00M.08\" progressive=\"False\" type=\"video\">, <Stream: itag=\"160\" mime_type=\"video/mp4\" res=\"144p\" fps=\"30fps\" vcodec=\"avc1.4d400c\" progressive=\"False\" type=\"video\">, <Stream: itag=\"278\" mime_type=\"video/webm\" res=\"144p\" fps=\"30fps\" vcodec=\"vp9\" progressive=\"False\" type=\"video\">, <Stream: itag=\"394\" mime_type=\"video/mp4\" res=\"144p\" fps=\"30fps\" vcodec=\"av01.0.00M.08\" progressive=\"False\" type=\"video\">, <Stream: itag=\"139\" mime_type=\"audio/mp4\" abr=\"48kbps\" acodec=\"mp4a.40.5\" progressive=\"False\" type=\"audio\">, <Stream: itag=\"140\" mime_type=\"audio/mp4\" abr=\"128kbps\" acodec=\"mp4a.40.2\" progressive=\"False\" type=\"audio\">, <Stream: itag=\"249\" mime_type=\"audio/webm\" abr=\"50kbps\" acodec=\"opus\" progressive=\"False\" type=\"audio\">, <Stream: itag=\"250\" mime_type=\"audio/webm\" abr=\"70kbps\" acodec=\"opus\" progressive=\"False\" type=\"audio\">, <Stream: itag=\"251\" mime_type=\"audio/webm\" abr=\"160kbps\" acodec=\"opus\" progressive=\"False\" type=\"audio\">]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from pytubefix import YouTube\n",
    "from modules.youtube import extract_youtube_video_id, get_video_metadata\n",
    "\n",
    "#video_url = \"https://youtu.be/JhU0yO43b6o?si=mfsiB2wajdY55US9\"\n",
    "\n",
    "video_url = \"https://youtu.be/x7X9w_GIm1s?si=QyrwdVD2lVmeontV\"\n",
    "video_id = extract_youtube_video_id(video_url)\n",
    "video_meta = get_video_metadata(video_url)\n",
    "\n",
    "audio_filename = video_meta['name']\n",
    "audio_filepath = os.path.join(\"..\", \"transcript_audios\", audio_filename)\n",
    "yt = YouTube(url=f\"https://www.youtube.com/watch?v={video_id}\")\n",
    "yt.streams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "download = yt.streams.get_audio_only().download(mp3=True, filename=audio_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/sudoleg/Projects/Personal/ytai/scripts/../transcript_audios/Python in 100 Seconds.mp3'"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "download"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate transcript via API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "api_key = os.getenv(\"OPENAI_YTAI_API_KEY\")\n",
    "client = OpenAI(api_key=api_key)\n",
    "\n",
    "audio_file= open(download, \"rb\")\n",
    "transcription = client.audio.transcriptions.create(\n",
    "  model=\"whisper-1\", \n",
    "  file=audio_file,\n",
    "  response_format=\"verbose_json\",\n",
    "  timestamp_granularities=['segment']\n",
    ")\n",
    "\n",
    "transcription_segments = [segment for segment in transcription.segments]\n",
    "transcription_text = transcription.text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate transcript locally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sudoleg/Projects/Personal/ytai/.venv/lib/python3.12/site-packages/whisper/__init__.py:146: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(fp, map_location=device)\n",
      "/Users/sudoleg/Projects/Personal/ytai/.venv/lib/python3.12/site-packages/whisper/transcribe.py:115: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
      "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution time: 8.90 seconds\n"
     ]
    }
   ],
   "source": [
    "import whisper\n",
    "import time\n",
    "\n",
    "# Start the timer\n",
    "start_time = time.time()\n",
    "\n",
    "model = whisper.load_model(\"base\")\n",
    "transcription = model.transcribe(download)\n",
    "\n",
    "# End the timer\n",
    "end_time = time.time()\n",
    "\n",
    "# Calculate the elapsed time\n",
    "execution_time = end_time - start_time\n",
    "print(f\"Execution time: {execution_time:.2f} seconds\")\n",
    "\n",
    "transcription_segments = [segment for segment in transcription['segments']]\n",
    "transcription_text = transcription['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Timemstamp: 0.00 - 0.05\n",
      " Python, a high-level, interpreted programming language famous for its zen-like code.\n",
      "---\n",
      "Timemstamp: 0.05 - 0.09\n",
      " It's arguably the most popular language in the world because it's easy to learn,\n",
      "---\n",
      "Timemstamp: 0.09 - 0.14\n",
      " yet practical for serious projects. In fact, you're watching this YouTube video in a Python web\n",
      "---\n",
      "Timemstamp: 0.14 - 0.19\n",
      " application right now. It was created by Kwiidovan Rossum and released in 1991, who named it after\n",
      "---\n",
      "Timemstamp: 0.19 - 0.25\n",
      " Monty Python's blind circus, which is why you'll sometimes find spam and eggs instead of food and bar\n",
      "---\n",
      "Timemstamp: 0.25 - 0.30\n",
      " in code samples. It's commonly used to build server-side applications, like web apps with the Django\n",
      "---\n",
      "Timemstamp: 0.30 - 0.35\n",
      " framework, and is the language of choice for big data analysis and machine learning. Many students\n",
      "---\n",
      "Timemstamp: 0.35 - 0.40\n",
      " choose Python to start learning to code because of its emphasis on readability as outlined by the zen\n",
      "---\n",
      "Timemstamp: 0.40 - 0.46\n",
      " of Python. Beautiful is better than ugly, while explicit is better than implicit. Python is very simple,\n",
      "---\n",
      "Timemstamp: 0.46 - 0.51\n",
      " but avoids the temptation to sprinkle in magic that causes ambiguity. Its code is often organized\n",
      "---\n",
      "Timemstamp: 0.51 - 0.56\n",
      " into notebooks, where individual cells can be executed, then documented in the same place.\n",
      "---\n",
      "Timemstamp: 0.56 - 1.00\n",
      " We're currently at version 3 of the language, and you can get started by creating a file that\n",
      "---\n",
      "Timemstamp: 1.00 - 1.06\n",
      " ends in .py, or .ipynb to create an interactive notebook. Create a variable by setting a name\n",
      "---\n",
      "Timemstamp: 1.06 - 1.11\n",
      " equal to a value. It's strongly typed, which means values won't change in unexpected ways,\n",
      "---\n",
      "Timemstamp: 1.11 - 1.16\n",
      " but dynamic, so type annotations are not required. The syntax is highly efficient, allowing you to\n",
      "---\n",
      "Timemstamp: 1.16 - 1.21\n",
      " declare multiple variables on a single line and define two pulls, lists, and dictionaries with a\n",
      "---\n",
      "Timemstamp: 1.21 - 1.25\n",
      " literal syntax. Semicolins are not required, and if you use them and experience Pythonista,\n",
      "---\n",
      "Timemstamp: 1.25 - 1.31\n",
      " we'll say that your code is not Pythonic. Instead of Semicolins, Python uses indentation to\n",
      "---\n",
      "Timemstamp: 1.31 - 1.36\n",
      " terminate or determine the scope of a line of code. Define a function with a def keyword, then indent\n",
      "---\n",
      "Timemstamp: 1.36 - 1.41\n",
      " the next line, usually by four spaces, to define the function body. We might then add a for loop to it,\n",
      "---\n",
      "Timemstamp: 1.41 - 1.45\n",
      " and indent that by another four spaces. This eliminates the need for curly braces and\n",
      "---\n",
      "Timemstamp: 1.45 - 1.50\n",
      " Semicolins found in many other languages. Python is a multi-paradigm language. We can apply\n",
      "---\n",
      "Timemstamp: 1.50 - 1.54\n",
      " functional programming patterns with things like anonymous functions using Lambda. It also uses\n",
      "---\n",
      "Timemstamp: 1.54 - 1.59\n",
      " objects as an abstraction for data, allowing you to implement object-oriented patterns, with things\n",
      "---\n",
      "Timemstamp: 1.59 - 2.05\n",
      " like classes and inheritance. It also has a huge ecosystem of third-party libraries, such as deep\n",
      "---\n",
      "Timemstamp: 2.05 - 2.09\n",
      " learning frameworks like TensorFlow, and wrappers for many high-performance low-level packages like\n",
      "---\n",
      "Timemstamp: 2.09 - 2.14\n",
      " Open Computer Vision, which are most often installed with the PIP package manager. This has been\n",
      "---\n",
      "Timemstamp: 2.14 - 2.18\n",
      " the Python programming language in 100 seconds. Hit the like button if you want to see more short\n",
      "---\n",
      "Timemstamp: 2.18 - 2.23\n",
      " videos like this. Thanks for watching, and I will see you in the next one.\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "for segment in transcription_segments:\n",
    "    start = seconds_to_minutes(float(segment['start']))\n",
    "    end = seconds_to_minutes(float(segment['end']))\n",
    "    print(f\"Timemstamp: {start} - {end}\")\n",
    "    print(segment['text'])\n",
    "    print(\"---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'dict' object has no attribute 'text'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[66], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmodules\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mhelpers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m save_response_as_file\n\u001b[0;32m----> 3\u001b[0m save_response_as_file(dir_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m../transcribed\u001b[39m\u001b[38;5;124m\"\u001b[39m, filename\u001b[38;5;241m=\u001b[39mvideo_meta[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m'\u001b[39m], file_content\u001b[38;5;241m=\u001b[39m\u001b[43mtranscription\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtext\u001b[49m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'dict' object has no attribute 'text'"
     ]
    }
   ],
   "source": [
    "from modules.helpers import save_response_as_file\n",
    "\n",
    "save_response_as_file(dir_name=\"../transcribed\", filename=video_meta['name'], file_content=transcription.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
